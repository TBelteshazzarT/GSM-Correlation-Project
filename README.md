# Geomagnetic Storm Prediction using Random Forest

## Project Overview

This project implements a Random Forest model to predict geomagnetic storms using the DST (Disturbance Storm Time) index and various heliospheric variables. The system processes OMNI data from NASA, performs feature selection, trains a Random Forest regressor, and evaluates the model's performance.

The work is inspired by the paper: "Machine learning models for predicting geomagnetic storms across five solar cycles using Dst index and heliospheric variables."

## Prerequisites

Before running the code, ensure you have the following installed:
- Python 3.7+
- Required Python packages:
  - pandas
  - numpy
  - scikit-learn
  - matplotlib
  - seaborn
  - urllib3

Install the dependencies using:
```bash
pip install pandas numpy scikit-learn matplotlib seaborn urllib3
```

## File Structure

```
project/
│
├── random_forest_driver.py        # Main script for training and evaluating the Random Forest model
├── paper_dataset_driver.py        # Script for initial data processing and visualization
├── OmniDataService.py             # Service for downloading and processing OMNI data from NASA
├── Modeling_Tools.py              # Utility functions for model saving/loading and metric calculation
├── processed_dat.csv              # Processed dataset (generated by paper_dataset_driver.py)
└── random_forest_results/         # Directory for storing model outputs
    ├── RF.pkl                     # Saved Random Forest model
    ├── RF_actual_v_pred.png       # Actual vs Predicted values plot
    ├── RF_feature_importance.png  # Feature importance plot
    └── _results.txt               # Model performance metrics
```

## Usage Instructions

### Step 1: Data Preparation
Run the data processing script first:
'paper_dataset_driver.py'


This script:
1. Downloads OMNI data from NASA (if not already present)
2. Processes the raw data
3. Generates visualizations of the time series and feature correlations
4. Saves the processed data to `processed_dat.csv`

### Step 2: Model Training and Evaluation
After the data is prepared, run the Random Forest model:
`random_forest_driver.py'

This script:
1. Loads the processed data
2. Splits the data into training and testing sets
3. Performs hyperparameter tuning (if enabled)
4. Trains a Random Forest regressor
5. Evaluates the model on test data
6. Generates visualizations of predictions and feature importance
7. Saves the model and results to the `random_forest_results` directory

## Key Features

### Data Processing
- Handles missing values by dropping NA values
- Selects relevant features for geomagnetic storm prediction:
  - Field Magnitude Average |B|
  - f10.7_index
  - Proton Density
  - Flow Pressure
  - Plasma (Flow) speed
  - Proton temperature
  - Na/Np
  - R (Sunspot number)
  - DST Index (target variable)

### Random Forest Model
- Hyperparameter tuning using GridSearchCV
- Key hyperparameters optimized:
  - n_estimators
  - ccp_alpha
  - criterion
  - max_depth
  - max_features
  - min_samples_leaf
  - min_samples_split
- Model persistence (saves/loads trained model)

### Evaluation Metrics
- Calculates and reports:
  - R-squared (coefficient of determination)
  - Mean Squared Error (MSE)
- Generates visualizations:
  - Actual vs Predicted values scatter plot
  - Feature importance bar chart

## Customization Options

### In `random_forest_driver.py`:
- Toggle hyperparameter tuning with `hyperparam_tuning` parameter
- Adjust base parameters in `params_base` dictionary
- Modify the feature set by changing `X_labels`

### In `paper_dataset_driver.py`:
- Adjust the time range with `years` parameter
- Modify the feature set for analysis by changing `features` list

## Results Interpretation

After running the scripts, check the `random_forest_results` directory for:
1. `_results.txt` - Contains performance metrics (R-squared and MSE for train/test sets)
2. `RF_actual_v_pred.png` - Shows how well predictions match actual values
3. `RF_feature_importance.png` - Visualizes which features are most important for predictions

## Notes

- The first run may take significant time due to data downloading and hyperparameter tuning (about 15 min)
- Subsequent runs will be faster as the model loads from the saved `.pkl` file (not included in the repository
- For large datasets, consider running on a machine with sufficient memory
- The absolute value of DST Index is used as target to ensure compatibility with Poisson distribution criterion

## References

This implementation follows methodologies from the paper:
"Machine learning models for predicting geomagnetic storms across five solar cycles using Dst index and heliospheric variables"

Data is sourced from NASA's OMNI database through the OMNIWeb service.
